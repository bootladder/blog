<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.4.3">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2017-10-27T18:30:18-07:00</updated><id>/</id><title type="html">Bootladder News</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</subtitle><entry><title type="html">jenkins and build inside a docker container</title><link href="/2017/10/27/jenkins-and-build-inside-a-docker-container.html" rel="alternate" type="text/html" title="jenkins and build inside a docker container" /><published>2017-10-27T00:00:00-07:00</published><updated>2017-10-27T00:00:00-07:00</updated><id>/2017/10/27/jenkins-and-build-inside-a-docker-container</id><content type="html" xml:base="/2017/10/27/jenkins-and-build-inside-a-docker-container.html">&lt;p&gt;Jenkins will be available through some URL.
The build toolchain will be installed in the Dockerfile,
on top of the jenkins image.&lt;/p&gt;

&lt;p&gt;Toolchain is static but the code isn’t so the code building
is done inside the container.  pulling the code, dependencies,
building it, etc is a script run inside the container.&lt;/p&gt;</content><author><name></name></author><summary type="html">Jenkins will be available through some URL. The build toolchain will be installed in the Dockerfile, on top of the jenkins image. Toolchain is static but the code isn’t so the code building is done inside the container. pulling the code, dependencies, building it, etc is a script run inside the container.</summary></entry><entry><title type="html">OpenVPN on Docker</title><link href="/2017/10/17/openvpn-on-docker.html" rel="alternate" type="text/html" title="OpenVPN on Docker" /><published>2017-10-17T00:00:00-07:00</published><updated>2017-10-17T00:00:00-07:00</updated><id>/2017/10/17/openvpn-on-docker</id><content type="html" xml:base="/2017/10/17/openvpn-on-docker.html">&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo curl -sSL https://get.docker.com/ | sudo sh
sudo usermod -aG docker ubuntu
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;httpsgithubcomkylemannadocker-openvpn&quot;&gt;https://github.com/kylemanna/docker-openvpn&lt;/h1&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;OVPN_DATA=&quot;ovpn-data-example&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;The volume stores data generated by the following.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker volume create --name $OVPN_DATA
  docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_genconfig -u udp://VPN.SERVERNAME.COM
sudo ls /var/lib/docker/volumes/ovpn-data-example/_data/
ccd  down.sh  openvpn.conf  ovpn_env.sh  up.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn ovpn_initpki
ubuntu@ubuntu:~$ sudo ls /var/lib/docker/volumes/ovpn-data-example/_data/
ccd  down.sh  openvpn.conf  ovpn_env.sh  pki  up.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run -v $OVPN_DATA:/etc/openvpn -d -p 1194:1194/udp --cap-add=NET_ADMIN kylemanna/openvpn
  docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full CLIENTNAME nopass
  docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient CLIENTNAME &amp;gt; CLIENTNAME.ovpn
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ubuntu@ubuntu:~$ ls
CLIENTNAME.ovpn 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">sudo curl -sSL https://get.docker.com/ | sudo sh sudo usermod -aG docker ubuntu https://github.com/kylemanna/docker-openvpn OVPN_DATA=&quot;ovpn-data-example&quot; The volume stores data generated by the following. docker volume create --name $OVPN_DATA docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_genconfig -u udp://VPN.SERVERNAME.COM sudo ls /var/lib/docker/volumes/ovpn-data-example/_data/ ccd down.sh openvpn.conf ovpn_env.sh up.sh docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn ovpn_initpki ubuntu@ubuntu:~$ sudo ls /var/lib/docker/volumes/ovpn-data-example/_data/ ccd down.sh openvpn.conf ovpn_env.sh pki up.sh docker run -v $OVPN_DATA:/etc/openvpn -d -p 1194:1194/udp --cap-add=NET_ADMIN kylemanna/openvpn docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full CLIENTNAME nopass docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient CLIENTNAME &amp;gt; CLIENTNAME.ovpn ubuntu@ubuntu:~$ ls CLIENTNAME.ovpn</summary></entry><entry><title type="html">Docker Swarm Beaglebone</title><link href="/2017/10/17/docker-swarm-beaglebone.html" rel="alternate" type="text/html" title="Docker Swarm Beaglebone" /><published>2017-10-17T00:00:00-07:00</published><updated>2017-10-17T00:00:00-07:00</updated><id>/2017/10/17/docker-swarm-beaglebone</id><content type="html" xml:base="/2017/10/17/docker-swarm-beaglebone.html">&lt;h1 id=&quot;first-the-swarm-manager&quot;&gt;First the Swarm Manager&lt;/h1&gt;
&lt;p&gt;Physical access to the Beaglebone allowed a startup script to be installed,
which would set up a reverse SSH tunnel to an Internet host.&lt;br /&gt;
Then, install and configure the Docker Swarm.&lt;/p&gt;

&lt;p&gt;The Swarm Manager needs to have a static IP on the LAN,
so the Swarm Nodes can hard code that static IP.&lt;/p&gt;

&lt;h1 id=&quot;the-swarm-nodes-will-all-use-the-same-sd-card-image&quot;&gt;The Swarm Nodes will all use the same SD card image&lt;/h1&gt;
&lt;p&gt;The filesystem in that SD card image can have a startup script with that
Manager Static IP hard coded in.&lt;/p&gt;</content><author><name></name></author><summary type="html">First the Swarm Manager Physical access to the Beaglebone allowed a startup script to be installed, which would set up a reverse SSH tunnel to an Internet host. Then, install and configure the Docker Swarm. The Swarm Manager needs to have a static IP on the LAN, so the Swarm Nodes can hard code that static IP. The Swarm Nodes will all use the same SD card image The filesystem in that SD card image can have a startup script with that Manager Static IP hard coded in.</summary></entry><entry><title type="html">cpputest on docker</title><link href="/2017/10/10/cpputest-on-docker.html" rel="alternate" type="text/html" title="cpputest on docker" /><published>2017-10-10T00:00:00-07:00</published><updated>2017-10-10T00:00:00-07:00</updated><id>/2017/10/10/cpputest-on-docker</id><content type="html" xml:base="/2017/10/10/cpputest-on-docker.html">&lt;p&gt;I’m going to build debos_firmware with a docker container.&lt;br /&gt;
I’ll start with apline linux, get a toolchain.&lt;br /&gt;
Then have it clone the debos_firmware repo and build it.&lt;/p&gt;</content><author><name></name></author><summary type="html">I’m going to build debos_firmware with a docker container. I’ll start with apline linux, get a toolchain. Then have it clone the debos_firmware repo and build it.</summary></entry><entry><title type="html">CMake and Gradle for ARM C/C++</title><link href="/2017/10/09/cmake-and-gradle-for-arm-c-c.html" rel="alternate" type="text/html" title="CMake and Gradle for ARM C/C++" /><published>2017-10-09T00:00:00-07:00</published><updated>2017-10-09T00:00:00-07:00</updated><id>/2017/10/09/cmake-and-gradle-for-arm-c-c</id><content type="html" xml:base="/2017/10/09/cmake-and-gradle-for-arm-c-c.html">&lt;p&gt;I’m trying to build my codebase in CMake or Gradle.&lt;br /&gt;
Tried Gradle first.  At first glance there are way too many DSL keywords,
I have no idea what they do and connecting the dots is insane.&lt;br /&gt;
It’s the same frustration I get with python.  Never knowing what type anything is
and always having to look up documentation before writing a single line.&lt;/p&gt;

&lt;p&gt;Now trying CMake…&lt;/p&gt;

&lt;p&gt;http://derekmolloy.ie/hello-world-introductions-to-cmake/&lt;/p&gt;

&lt;p&gt;I started with this CMakeLists.txt&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cmake_minimum_required(VERSION 2.8)
project(hello)
set(CMAKE_BINARY_DIR ${CMAKE_SOURCE_DIR}/bin)
set(EXECUTABLE_OUTPUT_PATH ${CMAKE_BINARY_DIR})
set(LIBRARY_OUTPUT_PATH ${CMAKE_BINARY_DIR})
include_directories(&quot;${PROJECT_SOURCE_DIR}&quot;)
add_executable(hello ${PROJECT_SOURCE_DIR}/src/main.c)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To build,&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cmake .
make
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Wow it actually tried to compile something.  No include directories were supplied.  Let’s add one.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;include_directories(myincludedir)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Works.  Now there’s another header that’s not inside the repo.&lt;br /&gt;
Let’s add those.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;include_directories(&quot;../samd20_cmsis_headers&quot;)
include_directories(&quot;../arm_cmsis_headers&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Next error, Error: no such instruction: `cpsie i’.&lt;br /&gt;
I must not be compling with the arm gcc compiler.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;set(CMAKE_C_COMPILER arm-none-eabi-gcc)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;arm-none-eabi-gcc: error: unrecognized command line option '-rdynamic'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now I get this error.  Found a solution from here.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://github.com/digitalbitbox/mcu/blob/master/arm.cmake
# Avoid known bug in linux giving: 
#    arm-none-eabi-gcc: error: unrecognized command line option '-rdynamic'
set(CMAKE_SHARED_LIBRARY_LINK_C_FLAGS &quot;&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;For the CFLAGS I used this syntax.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;set(CMAKE_C_FLAGS &quot;-std=c99                      &quot;)
string(APPEND CMAKE_C_FLAGS &quot;-Wall                         &quot;)
string(APPEND CMAKE_C_FLAGS &quot;-Wextra                       &quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I used this to add directories containing source files to be compiled.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;file(GLOB SOURCES
    &quot;src/*.h&quot;
    &quot;src/*.c&quot;
    &quot;src/hal/*.c&quot;
    &quot;src/hal/*.h&quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;And I changed the executable to be built from those sources:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;add_executable(myname ${SOURCES})
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I noticed the output of the GNU size command shows different sizes for the
ELF output from the CMake build and the original Makefile build.
  I realized I never specified the linker script.  Let’s do that.&lt;/p&gt;

&lt;p&gt;Turns out I just stick it in the CMAKE_C_FLAGS , no need for a separate linker flags.&lt;/p&gt;

&lt;p&gt;Added that and I get the desired output.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   text    data     bss     dec     hex filename     
  3352      68    2584    6004    1774 bin/debos_firmware  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Seeing that exact same output on either build is… extremely releiving.&lt;/p&gt;

&lt;h1 id=&quot;uh-now-im-trying-to-build-my-unit-test-executable&quot;&gt;Uh, now I’m trying to build my unit test executable.&lt;/h1&gt;

&lt;p&gt;I got this far …&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;file(GLOB TEST_SOURCES
    &quot;test/*.h&quot;
    &quot;test/*.c&quot;
    &quot;test/test_runners/*.c&quot;
    &quot;test/test_runners/*.h&quot;
    &quot;mock/*.c&quot;
    &quot;../Unity/src/*.c&quot;
    &quot;src/*.c&quot;
    &quot;src/hal/*.c&quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;First issue I have to deal with:&lt;br /&gt;
Multiple Definition error from the linker.&lt;br /&gt;
As you see, I included the test/ directory and src/.
Inside test there are some mocked objects.  The names collide with the ones from source.&lt;/p&gt;

&lt;p&gt;A solution I’ve learned from various books is to compile the source into a library.
When linking the test executable, the library will only be searched when the
symbol is not found in the test objects.&lt;br /&gt;
This hackish technique creates a priority of sorts, for names.  Test names first, production names second.&lt;/p&gt;

&lt;p&gt;Now how do I do this with CMake?  Reimplement that above logic?&lt;br /&gt;
My guess is Yes, because CMake just wraps make and it is make and gcc that are complaining
about not finding the symbols.&lt;/p&gt;

&lt;h1 id=&quot;create-a-static-library-of-the-application-code-and-link-it-to-the-test-exe&quot;&gt;Create a static library of the application code and link it to the test exe&lt;/h1&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;add_library(applib_debos_firmware STATIC ${SOURCES})
add_executable(test_debos_firmware ${TEST_SOURCES})
target_link_libraries(test_debos_firmware applib_debos_firmware )
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;First, the above CMakeLists.txt is inside the test/ directory.&lt;br /&gt;
So I have CMakeLists.txt inside both src/ and test/.&lt;br /&gt;
To build, I go inside a directory and run cmake, and the Makefile is generated in the directory.&lt;br /&gt;
Since the Makefile is now autogenerated, I now have it in .gitignore.&lt;/p&gt;

&lt;p&gt;The ${SOURCES} is a collection of source inside src/ , but does not include HAL.&lt;br /&gt;
HAL code is generally not compilable on host.&lt;br /&gt;
If there is a high level HAL like a UART driver then I’ll put that in src/ not hal/.&lt;/p&gt;

&lt;h1 id=&quot;so-far-this-is-good--next-i-want-the-dependencies-pulled-in-automatically&quot;&gt;So far this is good.  Next I want the dependencies pulled in automatically.&lt;/h1&gt;

&lt;p&gt;This particular project needs libraries:  unit test library, 
target specific headers repositories.&lt;/p&gt;

&lt;p&gt;Unit Test library is public URL, target specific headers are public git URL.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ExternalProject_Add(samd20_headers
    GIT_REPOSITORY &quot;https://bitbucket.org/bootladder/samd20_cmsis_headers&quot;
    BUILD_COMMAND &quot;&quot;
    UPDATE_COMMAND &quot;&quot;
    CONFIGURE_COMMAND &quot;&quot;
    INSTALL_COMMAND &quot;&quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This worked to get the repo downloaded.  The following showed up in my ls:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;drwxr-xr-x 4 steve supervisorusers 4.0K Oct 10 15:50 samd20_headers-prefix/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;What is this prefix business…  let’s put in a prefix.&lt;/p&gt;

&lt;p&gt;If I put in a&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PREFIX &quot;hello&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Then the repo is cloned, named hello.  what??&lt;br /&gt;
Apparently it’s supposed to be this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PREFIX &quot;samd20_headers&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Why do I have to explicitly type the same name…&lt;/p&gt;

&lt;h1 id=&quot;anyway-next-problem-is-the-include-path-is-no-longer-the-same&quot;&gt;Anyway, next problem is, the include path is no longer the same.&lt;/h1&gt;

&lt;p&gt;I need to tell CMake to add include directories to the compiler command.&lt;/p&gt;

&lt;h1 id=&quot;oh-prefix-is-for-where-the-external-project-is-installed--doesnt-have-to-be-inside-this-project&quot;&gt;Oh, prefix is for where the external project is installed.  Doesn’t have to be inside this project&lt;/h1&gt;

&lt;h1 id=&quot;moving-on-to-the-test-build-auto-downloading-the-unity-test-framework&quot;&gt;Moving on to the test build, auto downloading the Unity test framework&lt;/h1&gt;

&lt;p&gt;This one was tricky because it doesn’t provide a build script.
It is intended for the library consumer to build the source.&lt;br /&gt;
Also, the source is not in the top directory of the repo.&lt;/p&gt;

&lt;p&gt;I solved it with a kludge, don’t like it:&lt;/p&gt;

&lt;p&gt;First, this is how I added compiler include directories.&lt;br /&gt;
Using install_dir as a global variable here…&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ExternalProject_Get_Property(samd20_headers install_dir)
include_directories(${install_dir}/src/samd20_headers/)
ExternalProject_Get_Property(arm_cmsis_headers install_dir)
include_directories(${install_dir}/src/arm_cmsis_headers/)
ExternalProject_Get_Property(unity install_dir)
include_directories(${install_dir}/src/unity/src/)
include_directories(${install_dir}/src/unity/extras/fixture/src/)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Notice at the end, for unity, there are 2 calls to include_directories().
I guess it’s ok, it’s explicit and still relative to the ${install_dir}.&lt;/p&gt;

&lt;p&gt;Later, in my list of source files, there’s another kludge.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;file(GLOB TEST_SOURCES
    &quot;*.h&quot;
    &quot;*.c&quot;
    &quot;hal/*.c&quot;
    &quot;test_runners/*.c&quot;
    &quot;test_runners/*.h&quot;
    &quot;../../Unity/extras/fixture/src/*.c&quot;
    &quot;../mock/*.c&quot;
    &quot;../../Unity/src/*.c&quot;
    &quot;${install_dir}/src/unity/src/*&quot;
    &quot;${install_dir}/src/unity/extras/fixture/src/*&quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;But same, I guess it’s OK, because the list is explicit and also relative to ${install_dir}.&lt;br /&gt;
So every time this project is cloned and built it’ll work.&lt;br /&gt;
One issue is the name install_dir is only valid when install_dir was just written to with the correct contents.&lt;/p&gt;

&lt;h1 id=&quot;uhhh-a-similar-issue-build-doesnt-work-first-time-works-second-time&quot;&gt;Uhhh, a similar issue… Build doesn’t work first time, works second time?&lt;/h1&gt;

&lt;p&gt;What’s happening here…&lt;/p&gt;

&lt;p&gt;Same thing as before.  The Unity git repo was cloned, and then
Make is supposed to compile the source as part of the build.&lt;br /&gt;
But Make can’t find them.&lt;br /&gt;
In this case, Make did not include those sources in the list of source files to be compiled.&lt;br /&gt;
Make said “Scanning dependencies of…” and then compiled the sources, but the Unity sources weren’t.&lt;br /&gt;
All I have to do to get the build to succeed next time is:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;touch CMakeLists.txt
make
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;And it works; this time, it scans the dependencies, finds the Unity sources and builds them.&lt;/p&gt;

&lt;h1 id=&quot;i-guess-im-not-supposed-to-try-to-do-this&quot;&gt;I guess I’m not supposed to try to do this?&lt;/h1&gt;

&lt;p&gt;Why should I build the source ?  That means I have to know how to build it.&lt;br /&gt;
Any changes to that repo will break my build and everyone else who does it this way.&lt;/p&gt;

&lt;p&gt;What’s the alternative?  They can’t precompile unless they only supported a couple targets.&lt;br /&gt;
They could include a Makefile or CMakeLists.txt.  CMake would work I guess but not Make.&lt;/p&gt;

&lt;h1 id=&quot;lets-follow-this-one--httpwwwthrowtheswitchorgbuildcmake&quot;&gt;Let’s follow this one:  http://www.throwtheswitch.org/build/cmake&lt;/h1&gt;

&lt;p&gt;Since it is literally what I’m trying to do.&lt;/p&gt;

&lt;h1 id=&quot;eh-lets-get-ceedling-working-first&quot;&gt;Eh, let’s get Ceedling working first.&lt;/h1&gt;

&lt;p&gt;Currently I had handwritten Unity tests.&lt;br /&gt;
Ceedling does it a bit different.&lt;br /&gt;
Each test.c file is linked into a test app and executed.&lt;br /&gt;
It uses its own build system so anything that was in Make or CMake before
is invalid.&lt;br /&gt;
This means the linker and header dependencies on the production source.&lt;/p&gt;

&lt;p&gt;To get the ceedling tests to work you have to put #include statements
in the tests, which makes Ceedling pull in source files.&lt;br /&gt;
Other than that seems OK.&lt;/p&gt;

&lt;h1 id=&quot;problem-is-you-need-a-ruby-and-ceedling-installation&quot;&gt;Problem is you need a ruby and ceedling installation.&lt;/h1&gt;</content><author><name></name></author><summary type="html">I’m trying to build my codebase in CMake or Gradle. Tried Gradle first. At first glance there are way too many DSL keywords, I have no idea what they do and connecting the dots is insane. It’s the same frustration I get with python. Never knowing what type anything is and always having to look up documentation before writing a single line. Now trying CMake… http://derekmolloy.ie/hello-world-introductions-to-cmake/ I started with this CMakeLists.txt cmake_minimum_required(VERSION 2.8) project(hello) set(CMAKE_BINARY_DIR ${CMAKE_SOURCE_DIR}/bin) set(EXECUTABLE_OUTPUT_PATH ${CMAKE_BINARY_DIR}) set(LIBRARY_OUTPUT_PATH ${CMAKE_BINARY_DIR}) include_directories(&quot;${PROJECT_SOURCE_DIR}&quot;) add_executable(hello ${PROJECT_SOURCE_DIR}/src/main.c) To build, cmake . make Wow it actually tried to compile something. No include directories were supplied. Let’s add one. include_directories(myincludedir) Works. Now there’s another header that’s not inside the repo. Let’s add those. include_directories(&quot;../samd20_cmsis_headers&quot;) include_directories(&quot;../arm_cmsis_headers&quot;)</summary></entry><entry><title type="html">Reverse SSH access to beaglebone</title><link href="/2017/10/05/reverse-ssh-access-to-beaglebone.html" rel="alternate" type="text/html" title="Reverse SSH access to beaglebone" /><published>2017-10-05T00:00:00-07:00</published><updated>2017-10-05T00:00:00-07:00</updated><id>/2017/10/05/reverse-ssh-access-to-beaglebone</id><content type="html" xml:base="/2017/10/05/reverse-ssh-access-to-beaglebone.html">&lt;p&gt;I’m leaving for the weekend and I want access to my 2 beaglebones.&lt;br /&gt;
1 is my system under test, the other controls a USB programmer
that can flash a microcontroller on the SUT.&lt;/p&gt;

&lt;p&gt;Following this guide http://xmodulo.com/access-linux-server-behind-nat-reverse-ssh-tunnel.html&lt;/p&gt;

&lt;p&gt;First I’ll locally SSH into the beaglebone.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;homeserver~$ ssh -fN -R 10022:localhost:22 relayserver_user@1.1.1.1 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;-R for reverse tunnel.  Port 10022 on remote host is forwarded to port 22 on beaglebone&lt;/li&gt;
  &lt;li&gt;10022 is arbitrary&lt;/li&gt;
  &lt;li&gt;port 22 is the SSH port that beaglebone sshd is listening on&lt;/li&gt;
  &lt;li&gt;-f for background&lt;/li&gt;
  &lt;li&gt;-N for “don’t execute a command”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note:  I forgot that my VPS had disabled password logins; only permitted by key.&lt;br /&gt;
I had only installed 1 key on the VPS:  for my main laptop.&lt;br /&gt;
So to install 2 more keys, I SSHed into the VPS with my main laptop.&lt;br /&gt;
Temporarily allowed password logins.&lt;br /&gt;
Then used ssh-copy-id to install the keys on VPS.&lt;br /&gt;
Finally, disable password logins again.&lt;/p&gt;

&lt;p&gt;Last step is to add the command in rc.local.&lt;/p&gt;

&lt;h1 id=&quot;couple-extra-details&quot;&gt;Couple extra details&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;One of the beaglebones was running SSH on port 6000.  So, I had to change the 22 to a 6000.
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;homeserver~$ ssh -fN -R 10022:localhost:6000 relayserver_user@1.1.1.1 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;One of the beaglebones was only accepting SSH logins by key, but it only accepted one of a static set of keys.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This was annoying, I had to scp the key over to the VPS.  Then to login to the beaglebone thru the tunnel,
I had to supply the key with ssh -i.&lt;/p&gt;

&lt;h1 id=&quot;important-detail-for-having-2-tunnels&quot;&gt;Important detail for having 2+ tunnels&lt;/h1&gt;

&lt;p&gt;The port 10022 is arbitrary but if there are 2 tunnels they can’t be both on 10022.&lt;br /&gt;
So actually one of them was on 10023.&lt;br /&gt;
When SSHing through the tunnel I specified which tunnel by specifying the port.&lt;/p&gt;

&lt;h1 id=&quot;dang-the-ssh-connection-disconnected-overnight&quot;&gt;Dang, the SSH connection disconnected overnight.&lt;/h1&gt;

&lt;p&gt;Using AutoSSH 
https://www.everythingcli.org/ssh-tunnelling-for-fun-and-profit-autossh/&lt;/p&gt;

&lt;p&gt;Looks promising, I just used standard config.&lt;br /&gt;
Let’s see if it stays up!&lt;/p&gt;</content><author><name></name></author><summary type="html">I’m leaving for the weekend and I want access to my 2 beaglebones. 1 is my system under test, the other controls a USB programmer that can flash a microcontroller on the SUT. Following this guide http://xmodulo.com/access-linux-server-behind-nat-reverse-ssh-tunnel.html First I’ll locally SSH into the beaglebone.</summary></entry><entry><title type="html">Keep my hosts running</title><link href="/2017/10/04/keep-my-hosts-running.html" rel="alternate" type="text/html" title="Keep my hosts running" /><published>2017-10-04T00:00:00-07:00</published><updated>2017-10-04T00:00:00-07:00</updated><id>/2017/10/04/keep-my-hosts-running</id><content type="html" xml:base="/2017/10/04/keep-my-hosts-running.html">&lt;p&gt;Now that I temporarily host my friend’s site who actually wants to have visitors,
I can’t let it go down.  Also this blog, might as well keep it up.&lt;/p&gt;

&lt;p&gt;So first, when the VPS host goes down and reboots my VPS, my VPS has to start up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reverse Proxy, blog, friend’s site&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;systemd service looks OK but… feel safer with a shell script.&lt;/p&gt;

&lt;p&gt;To get this going, I’ll reboot the VPS and repeat the steps.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;service docker start;
cd /opt/nginx-proxy/ ; docker-compose up &amp;amp;
cd /opt/deploy/ ; docker-compose up &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;stick it in rc.local&lt;/p&gt;

&lt;p&gt;nice!&lt;/p&gt;

&lt;p&gt;Now how about a way to check if the website ever goes down?&lt;br /&gt;
Well if the host goes down it can’t tell me about it.&lt;br /&gt;
So, it could be the stopping of keepalive messages out of the host,
or a different host being unable to connect to the host.&lt;/p&gt;

&lt;p&gt;eh, leave that one at that for now.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;l&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Now that I temporarily host my friend’s site who actually wants to have visitors, I can’t let it go down. Also this blog, might as well keep it up. So first, when the VPS host goes down and reboots my VPS, my VPS has to start up.</summary></entry><entry><title type="html">beaglebone MCU programmer unit</title><link href="/2017/10/04/beaglebone-mcu-programmer-unit.html" rel="alternate" type="text/html" title="beaglebone MCU programmer unit" /><published>2017-10-04T00:00:00-07:00</published><updated>2017-10-04T00:00:00-07:00</updated><id>/2017/10/04/beaglebone-mcu-programmer-unit</id><content type="html" xml:base="/2017/10/04/beaglebone-mcu-programmer-unit.html">&lt;p&gt;I’m flashing Atmel ARM microcontrollers with a USB programmer dongle.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://github.com/bootladder/edbg
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Got a fresh beaglebone running, grabbed the IP from the local router.&lt;br /&gt;
In order to get the git clone to work I had to get the time right.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install ntp
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;the compiled edbg binary is not included so it must be installed.&lt;br /&gt;
Let’s write the install script here.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp libudev.h /usr/include;
cp libudev.so /lib ;
make;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Hmm looks like the library I included in there is out of date.  libc perhaps?&lt;/p&gt;

&lt;p&gt;Fortunately it worked after a&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install libudev-dev 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;So I’ll just take that copy of libudev.so out of the repo.&lt;/p&gt;

&lt;p&gt;So now it looks like this&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install libudev-dev
make;
cp edbg /bin/;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then I run a&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@beaglebone:/tmp# edbg -l
Attached debuggers:
  J41800059345 - Atmel Corp. Atmel-ICE CMSIS-DAP
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Sweet!&lt;/p&gt;</content><author><name></name></author><summary type="html">I’m flashing Atmel ARM microcontrollers with a USB programmer dongle. https://github.com/bootladder/edbg Got a fresh beaglebone running, grabbed the IP from the local router. In order to get the git clone to work I had to get the time right. apt-get install ntp the compiled edbg binary is not included so it must be installed. Let’s write the install script here. cp libudev.h /usr/include; cp libudev.so /lib ; make; Hmm looks like the library I included in there is out of date. libc perhaps? Fortunately it worked after a apt-get install libudev-dev So I’ll just take that copy of libudev.so out of the repo. So now it looks like this apt-get install libudev-dev make; cp edbg /bin/; Then I run a root@beaglebone:/tmp# edbg -l Attached debuggers: J41800059345 - Atmel Corp. Atmel-ICE CMSIS-DAP Sweet!</summary></entry><entry><title type="html">Use Phone WiFi Hotspot as default gateway for LAN</title><link href="/2017/09/18/use-phone-wifi-hotspot-as-default-gateway-for-lan.html" rel="alternate" type="text/html" title="Use Phone WiFi Hotspot as default gateway for LAN" /><published>2017-09-18T00:00:00-07:00</published><updated>2017-09-18T00:00:00-07:00</updated><id>/2017/09/18/use-phone-wifi-hotspot-as-default-gateway-for-lan</id><content type="html" xml:base="/2017/09/18/use-phone-wifi-hotspot-as-default-gateway-for-lan.html">&lt;p&gt;Big telecom companies are garbage.  Turd sandwich or giant douche?&lt;br /&gt;
Comcast: 1 year contract for $100/mo, 50Mb down.  No thanks!&lt;br /&gt;
Let’s look into mobile internet with unlimited data.  Let’s see if I can do this with my phone.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First I grab an extra laptop that has both Ethernet and WiFi.  This is the gateway&lt;/li&gt;
  &lt;li&gt;I turn on my phone’s hotspot and connect to it with the gateway laptop&lt;/li&gt;
  &lt;li&gt;Verify I can ping the gateway laptop from my tester client&lt;/li&gt;
  &lt;li&gt;Change default gateway on tester client to 10.0.0.6, verify Internet is now unavailable&lt;/li&gt;
  &lt;li&gt;On the gateway laptop, run this&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo sysctl -w net.ipv4.ip_forward=1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now Internet is available through gateway laptop, but the gateway now has to go out the WiFi hotspot.&lt;/p&gt;

&lt;p&gt;Turns out there are 2 0.0.0.0 entries in the route table.  Let’s delete the one for Ethernet and keep the WiFi one.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;route del default gateway x.x.x.x
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Hmm, ping doesn’t work.  Just hangs, no ouptut.  I see what’s happening using tcpdump … traffic starts at the tester client, gets to the gateway on the Ethernet interface, then goes out the WiFi interface, but the source address is still the tester client’s source.&lt;br /&gt;
If I run a ping on the gateway laptop, it does go through.  The obvious difference is the source address.  Let’s change that.&lt;/p&gt;

&lt;p&gt;Let’s try this one&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# iptables -t nat -A POSTROUTING ! -d 192.168.0.0/16 -o eth1 -j SNAT --to-source 1.2.3.4
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;wow-that-made-it-work&quot;&gt;Wow, that made it work!&lt;/h1&gt;</content><author><name></name></author><summary type="html">Big telecom companies are garbage. Turd sandwich or giant douche? Comcast: 1 year contract for $100/mo, 50Mb down. No thanks! Let’s look into mobile internet with unlimited data. Let’s see if I can do this with my phone. First I grab an extra laptop that has both Ethernet and WiFi. This is the gateway I turn on my phone’s hotspot and connect to it with the gateway laptop Verify I can ping the gateway laptop from my tester client Change default gateway on tester client to 10.0.0.6, verify Internet is now unavailable On the gateway laptop, run this sudo sysctl -w net.ipv4.ip_forward=1 Now Internet is available through gateway laptop, but the gateway now has to go out the WiFi hotspot. Turns out there are 2 0.0.0.0 entries in the route table. Let’s delete the one for Ethernet and keep the WiFi one. route del default gateway x.x.x.x Hmm, ping doesn’t work. Just hangs, no ouptut. I see what’s happening using tcpdump … traffic starts at the tester client, gets to the gateway on the Ethernet interface, then goes out the WiFi interface, but the source address is still the tester client’s source. If I run a ping on the gateway laptop, it does go through. The obvious difference is the source address. Let’s change that. Let’s try this one # iptables -t nat -A POSTROUTING ! -d 192.168.0.0/16 -o eth1 -j SNAT --to-source 1.2.3.4 Wow, that made it work!</summary></entry><entry><title type="html">Making my version control not suck</title><link href="/2017/09/13/making-my-version-control-not-suck.html" rel="alternate" type="text/html" title="Making my version control not suck" /><published>2017-09-13T00:00:00-07:00</published><updated>2017-09-13T00:00:00-07:00</updated><id>/2017/09/13/making-my-version-control-not-suck</id><content type="html" xml:base="/2017/09/13/making-my-version-control-not-suck.html">&lt;p&gt;I develop and maintain firmware for a family of products.
There are 5 different firmware projects here.
They’re all releated in communication protocol, as well as other things
such as beep frequency, LED blink patterns etc.&lt;/p&gt;

&lt;p&gt;But now I’m faced with splitting all 5 of those into 3 versions.
So now there are technically 15 different firmware images that need to be
available for download and documented to identify what they are.&lt;/p&gt;

&lt;p&gt;My (git) version control system until now was obvious.  Master goes forward, occasional branching and merging, tags on version releases.&lt;/p&gt;

&lt;p&gt;It would be possible to use branches and tags to rebuild any version of any project.  But here’s the complication:  there is a in-house shared library used by all 15 firmware versions.  That library also has 3 versions.  In other words the correct version of the shared library has to be available when building a version of firmware.
  In more other words, to build a version of firmware, the project repo has to be checked out at the right version, as well as the shared library checked out at the right version.  Finally, the build config (eg. Makefile) has to identify and locate the correct shared library to be linked.&lt;/p&gt;

&lt;p&gt;I like stuff like Ruby, Rust, etc. where you have a config file (yaml) to specify dependencies.&lt;/p&gt;

&lt;p&gt;I think I can improve my Makefile to do what I want.&lt;br /&gt;
It would be as simple as git checkout my_commit followed by make.
The Makefile at this commit should build the proper version.  The Makefile itself identifies its own version and the dependency versions it needs.  It can then git clone the dependencies using git submodules.&lt;/p&gt;

&lt;p&gt;This way, a complete build with all dependencies lives inside 1 directory.  If a submodule is updated or branched, it won’t affect previous builds.&lt;/p&gt;

&lt;h1 id=&quot;strategy--use-a-fresh-machine-vps-to-recreate-the-build&quot;&gt;Strategy:  use a fresh machine (VPS) to recreate the build&lt;/h1&gt;

&lt;p&gt;I don’t want to be confused with currently existing directory structure.  Building the same firmware version on a different machine is a good way to shake out things like hard coded paths breaking.&lt;br /&gt;
Ideally all builds would happen on this separate machine.  I guess that’s part of Continous Integration?&lt;/p&gt;

&lt;h1 id=&quot;-makefile-needs-source-located-in-a-hard-coded-directory&quot;&gt;— Makefile needs source located in a hard coded directory&lt;/h1&gt;

&lt;p&gt;Project needs a library or some source somewhere else to compile.
The Makefile can find the source with a VPATH and find the headers
with -I compiler flags.  But, that enforces a certain directory structure.&lt;/p&gt;

&lt;h1 id=&quot;-new-rule-discovery-only-create-directory-structure-for-sub-directories--never-depend-on-paths-starting-wtih--or--etc&quot;&gt;— New rule discovery?: Only create directory structure for sub-directories.  Never depend on paths starting wtih ../ or ../../ etc.&lt;/h1&gt;

&lt;p&gt;This rule allows you to create directory structure, but doesn’t cause problems because the structure is all below current directory.&lt;br /&gt;
Basically, enforced sub-directory structure is coupled entirely to
the populating of that sub-directory and makes no assumptions about directories above current directory.&lt;br /&gt;
In other words, if you have enforced structure, the build system has to automatically conform to that structure.  Let the Makefile create the directories with their correct names, populate them with files.&lt;/p&gt;

&lt;h1 id=&quot;-vpath-issue-with-git-clone&quot;&gt;— VPATH Issue with git clone&lt;/h1&gt;

&lt;p&gt;I have a repo prereq inside my all target.
The purpose is to clone the dependencies,
so Make can then refer to those dependencies and build the target.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;always: 
repos: always
        @echo hello
        if [ ! -d &quot;../../mysrcrepo&quot; ] ; then \
            git clone https://mysrcrepo ;\
        fi 
        if [ ! -d &quot;../../mylibrepo&quot; ] ; then \
            git clone https://mylibrepo ;\
            make; \

        fi 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It almost worked.
  In the case of a cloned library, the make command is run, which builds the library.  That worked.
  But in the case of cloned source, the VPATH didn’t catch the source files that were cloned.  When running make a second time, it would work.&lt;/p&gt;

&lt;p&gt;Well apparently 2 things are wrong with that, as I’ve read.&lt;br /&gt;
1, VPATH doesn’t work on generated files.  Not sure what that means specifically but the way I made sense of it is this:  You can add directories to VPATH but if they don’t exist when make is run, the VPATH won’t see that directory.  Even if the file exists at the time it is needed, it won’t be found.  That explains why the build works the second time.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Recursive Make Considered Harmful?&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;discovery--how-to-do-git-inside-make&quot;&gt;Discovery:  how to do git inside make&lt;/h1&gt;

&lt;p&gt;https://stackoverflow.com/questions/15602059/git-shortcut-to-pull-with-clone-if-no-local-there-yet&lt;/p&gt;

&lt;p&gt;Using this I can solve the problem in the above snippet
        if [ ! -d “../../mysrcrepo” ] ; then \&lt;/p&gt;

&lt;p&gt;If the directory does exist, nothing happens.  What I want is a git pull in that case.&lt;/p&gt;</content><author><name></name></author><summary type="html">I develop and maintain firmware for a family of products. There are 5 different firmware projects here. They’re all releated in communication protocol, as well as other things such as beep frequency, LED blink patterns etc.</summary></entry></feed>